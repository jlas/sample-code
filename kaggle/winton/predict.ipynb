{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "from odo import odo\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "df_test = pd.read_csv('test_2.csv')\n",
    "\n",
    "X = df.copy()\n",
    "X_test = df_test.copy()\n",
    "Y = df.loc[:,'Ret_121':'Ret_PlusTwo'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# winton evaluation function\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.regression import _check_reg_targets\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "# use regex to rename columns for simple selection\n",
    "wmae_cols = list(Y.columns)\n",
    "wmae_cols = map(lambda x: re.sub('Ret_[0-9]+', 'Weight_Intraday', x), wmae_cols)\n",
    "wmae_cols = map(lambda x: re.sub('Ret.*', 'Weight_Daily', x), wmae_cols)\n",
    "wmae_weights = df[wmae_cols]\n",
    "\n",
    "def weighted_mean_absolute_error(y_pred, y_true, weights):\n",
    "    output_errors = np.multiply(np.abs(y_pred - y_true), weights)\n",
    "    return np.average(np.average(output_errors, axis=1))\n",
    "\n",
    "# test, result should be 2.875\n",
    "# weighted_mean_absolute_error(\n",
    "#      np.array([[1.5,2.5],[6,8]]),\n",
    "#      np.array([[1,2],[3,4]]),\n",
    "#      np.array([2,1]))\n",
    "\n",
    "def wmae_score(estimator, X, y_true):\n",
    "    y_pred = estimator.predict(X)\n",
    "    weights = wmae_weights.iloc[X.index]\n",
    "    return weighted_mean_absolute_error(y_pred, y_true, weights)\n",
    "\n",
    "def write_predictions(Y_hat):\n",
    "    Y_hat = odo(Y_hat, pd.DataFrame)\n",
    "    Y_hat.columns += 1\n",
    "    Y_hat.index += 1\n",
    "    Y_hat = Y_hat.stack().reset_index()\n",
    "    Y_hat = odo(Y_hat, pd.DataFrame)\n",
    "    Y_hat = Y_hat.rename(columns={0:'Predicted'})\n",
    "    Y_hat.index = Y_hat[['level_0', 'level_1']].applymap(str).apply(\n",
    "        lambda x: '_'.join(x), axis=1)\n",
    "    Y_hat.index.name = 'Id'\n",
    "    Y_hat = Y_hat.drop(['level_0', 'level_1'], axis=1)\n",
    "    Y_hat.to_csv('predictions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fmt = lambda x: 'Feature_{}'.format(x)\n",
    "\n",
    "# some features seem to be categories\n",
    "_features = [1,5,8,9,10,13,16,20]\n",
    "feature_cats = {fmt(i): df[fmt(i)].dropna().unique() for i in _features}\n",
    "feature_cats\n",
    "\n",
    "# model feature distribution\n",
    "from scipy import stats\n",
    "features_dist = {\n",
    "    'norm': [2,3,4,11,14,17,18,19,21,22,23,24,25],\n",
    "    'beta': [12],\n",
    "    'uniform': [7],\n",
    "    'expon': [6, 15]\n",
    "}\n",
    "\n",
    "features_coeff = {}\n",
    "for _dist, _features in features_dist.items():\n",
    "    for _feature in _features:\n",
    "        _coeff = getattr(stats, _dist).fit(df[fmt(_feature)].dropna())\n",
    "        features_coeff[fmt(_feature)] = {\n",
    "            'type': _dist,\n",
    "            'coeff': _coeff\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def corrpair(df):\n",
    "    df = df.drop(['Id','Weight_Daily','Weight_Intraday'], 1)\n",
    "    dfc = df.corr()\n",
    "    dfcs = dfc.stack().sort_index()\n",
    "    dfcs = dfcs[(dfcs<1)&(dfcs>-1)&(~dfcs.duplicated())]\n",
    "    return abs(dfcs).sort_values(ascending=False)\n",
    "\n",
    "# get highest correlation pairs\n",
    "dfcs = corrpair(df)\n",
    "top_cp = dfcs.head(20)\n",
    "\n",
    "nuke_features = set([i[1] for i in top_cp[top_cp>0.75].index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, RegressorMixin\n",
    "from sklearn.dummy import DummyRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.utils.validation import check_array, check_consistent_length\n",
    "\n",
    "# sample from a series probabilistically according to the distribution of values\n",
    "def sample_per_distribution(s):\n",
    "    return s.dropna().sample(n=s.size, replace=True).reset_index(drop=True)\n",
    "\n",
    "def sample(s):\n",
    "    _d = features_coeff[s.name]\n",
    "    sample_fn = getattr(stats, _d['type']).rvs\n",
    "    return odo(sample_fn(*_d['coeff'], size=s.size), pd.Series)\n",
    "\n",
    "def fillall0(df):\n",
    "    return df.fillna(0)\n",
    "\n",
    "def fillall(df):\n",
    "    _x_base = df.loc[:,'Feature_1':'Feature_25'].copy()\n",
    "    _x_base = _x_base.fillna(_x_base[feature_cats.keys()].apply(sample_per_distribution))\n",
    "    _x_base = _x_base.fillna(_x_base[features_coeff.keys()].apply(sample))\n",
    "    return _x_base\n",
    "\n",
    "def fillall2(df):\n",
    "    _x = df.copy()\n",
    "    for features, samplefn in [(feature_cats.keys(), sample_per_distribution),\n",
    "                               (features_coeff.keys(), sample)]:\n",
    "        if not set(features).issubset(_x.columns):\n",
    "            continue\n",
    "        _x = _x.fillna(_x[features].apply(samplefn))\n",
    "\n",
    "    start_ret = 'Ret_121'\n",
    "    if 'Ret_2' in _x.columns:\n",
    "        start_ret = 'Ret_2'\n",
    "    end_ret = 'Ret_120'\n",
    "    if 'Ret_180' in _x.columns:\n",
    "        end_ret = 'Ret_180'\n",
    "\n",
    "    _x.loc[:,start_ret:end_ret].fillna(method='ffill', inplace=True)\n",
    "    _x.fillna(0,inplace=True)\n",
    "    return _x\n",
    "\n",
    "class NormRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        y = check_array(y, ensure_2d=False)\n",
    "        if len(y) == 0:\n",
    "            raise ValueError(\"y must not be empty.\")\n",
    "        \n",
    "        check_consistent_length(X, y, sample_weight)\n",
    "        \n",
    "        self._coeff = odo(y, pd.DataFrame).apply(stats.norm.fit)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not hasattr(self, \"_coeff\"):\n",
    "            raise ValueError(\"NormRegressor not fitted.\")\n",
    "\n",
    "        out = self._coeff.apply(\n",
    "            lambda x: pd.Series(stats.norm.rvs(x[0], 0.001*x[1], size=X.shape[0]))).T\n",
    "        return out.values\n",
    "\n",
    "    \n",
    "class NormRowRegressor(BaseEstimator, RegressorMixin):\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = pd.DataFrame()\n",
    "\n",
    "        daily_mean = .001*X.loc[:,'Ret_MinusTwo':'Ret_MinusOne'].mean(axis=1)\n",
    "        out['Ret_PlusOne'] = out['Ret_PlusTwo'] = daily_mean   \n",
    "\n",
    "        intra_mean = .001*X.loc[:, 'Ret_2':'Ret_120'].mean(axis=1)\n",
    "        for idx in xrange(121,181):\n",
    "            out['Feature_{}'.format(idx)] = intra_mean\n",
    "\n",
    "        return out.values\n",
    "\n",
    "\n",
    "# creates a regressor with customizable inputs/features,\n",
    "# predicts the median of the outputs/targets\n",
    "class FeatureMeanRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, features=None, regressor=None):\n",
    "        if regressor is None:\n",
    "            regressor = LinearRegression()\n",
    "        self._regressor = regressor\n",
    "        if features is None:\n",
    "            features = filter(lambda x: x.startswith('Feature'),list(df.columns))\n",
    "        self._features = list(features)\n",
    "        super(FeatureMeanRegressor, self).__init__()\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        _y = X.loc[:,'Ret_2':'Ret_180'].median(axis=1)\n",
    "        _x = X[self._features]\n",
    "        self._clf = self._regressor.fit(_x, _y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _x = X[self._features]\n",
    "        out = pd.DataFrame() \n",
    "        means = self._clf.predict(_x)\n",
    "        for idx in xrange(121,181):\n",
    "            out['Ret_{}'.format(idx)] = means\n",
    "        out['Ret_PlusOne'] = out['Ret_PlusTwo'] = 0\n",
    "        return out.values\n",
    "\n",
    "\n",
    "# creates a regressor with customizable inputs/features,\n",
    "# predicts the median of the outputs/targets\n",
    "class FeatureMeanRegressor2(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, features=None, outputs=None, regressor=None):\n",
    "        if regressor is None:\n",
    "            regressor = LinearRegression()\n",
    "        self._regressor = regressor\n",
    "        if features is None:\n",
    "            features = filter(lambda x: x.startswith('Feature'),list(df.columns))\n",
    "        self._features = list(features)\n",
    "        if outputs is None:\n",
    "            outputs = ['Ret_121','Ret_180']\n",
    "        self._output_start = outputs[0]\n",
    "        self._output_end = outputs[1]\n",
    "        super(FeatureMeanRegressor2, self).__init__()\n",
    "\n",
    "    def _get_output(self, X):\n",
    "        return X.loc[:,self._output_start:self._output_end]\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        _y = self._get_output(X).median(axis=1)\n",
    "        _x = X[self._features]\n",
    "        self._clf = self._regressor.fit(_x, _y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _x = X[self._features]\n",
    "        out = pd.DataFrame(columns=df.loc[:,'Ret_MinusTwo':'Ret_PlusTwo'].columns)\n",
    "        means = self._clf.predict(_x)\n",
    "        \n",
    "        subcols = out.loc[:,self._output_start:self._output_end].columns\n",
    "        for subcol in subcols:\n",
    "            out[subcol] = means\n",
    "\n",
    "        #out = out.fillna(0)\n",
    "        return out.loc[:,'Ret_121':'Ret_PlusTwo'].values    \n",
    "\n",
    "\n",
    "# creates a regressor with customizable inputs/features,\n",
    "# predicts the median of the outputs/targets\n",
    "class RetMeanRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def __init__(self, returns=None, features=None, outputs=None, regressor=None):\n",
    "        if regressor is None:\n",
    "            regressor = LinearRegression()\n",
    "        self._regressor = regressor\n",
    "        if returns is None:\n",
    "            returns = ['Ret_2','Ret_120']\n",
    "        self._returns = returns\n",
    "        if features is None:\n",
    "            features = filter(lambda x: x.startswith('Feature'),list(df.columns))\n",
    "        self._features = list(features)\n",
    "        if outputs is None:\n",
    "            outputs = ['Ret_2','Ret_180']\n",
    "        self._output_start = outputs[0]\n",
    "        self._output_end = outputs[1]\n",
    "        super(RetMeanRegressor, self).__init__()\n",
    "\n",
    "    def _get_output(self, X):\n",
    "        return X.loc[:,self._output_start:self._output_end]\n",
    "    \n",
    "    def _get_returns(self, X):\n",
    "        return odo(X.loc[:,self._returns[0]:self._returns[1]].median(axis=1), pd.DataFrame)\n",
    "    \n",
    "    def _get_features(self, X):\n",
    "        rets = self._get_returns(X)\n",
    "        return pd.concat([rets, X[self._features]], axis=1)\n",
    "    \n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        _y = self._get_output(X).median(axis=1)\n",
    "        _x = self._get_features(X)\n",
    "        self._clf = self._regressor.fit(_x, _y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        _x = self._get_features(X)\n",
    "        out = pd.DataFrame(columns=df.loc[:,'Ret_MinusTwo':'Ret_PlusTwo'].columns)\n",
    "        means = self._clf.predict(_x)\n",
    "        \n",
    "        subcols = out.loc[:,self._output_start:self._output_end].columns\n",
    "        for subcol in subcols:\n",
    "            out[subcol] = means\n",
    "\n",
    "        #out = out.fillna(0)\n",
    "        return out.loc[:,'Ret_121':'Ret_PlusTwo'].values    \n",
    "    \n",
    "\n",
    "# combines DummyRegressor and NormRowRegressor\n",
    "class JointRegressor(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def fit(self, X, y, weights=None):\n",
    "        self._weights = weights\n",
    "        self._dr = DummyRegressor(strategy='median')\n",
    "        self._dr.fit(X, y)\n",
    "        self._nrr = NormRowRegressor()\n",
    "        self._nrr.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        out1 = self._dr.predict(X)\n",
    "        out2 = self._nrr.predict(X)\n",
    "        return np.average(np.swapaxes(np.array([out1, out2]), 0, 1),\n",
    "                          axis=1, weights=self._weights)\n",
    "\n",
    "\n",
    "# combines DummyRegressor, NormRowRegressor, and other arbitrary regressors with fixed weighting\n",
    "class JointRegressor2(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def _get_xrtns(self, X):\n",
    "        X_returns = X.loc[:,'Ret_MinusTwo':'Ret_120'].reset_index(drop=True)\n",
    "        return X_returns.fillna(X_returns.apply(sample_per_distribution))\n",
    "    \n",
    "    def fit(self, X, y, weights=None, other_clf=None):\n",
    "        X_returns = self._get_xrtns(X)\n",
    "        self._weights = weights\n",
    "        self._dr = DummyRegressor(strategy='median')\n",
    "        self._dr.fit(X, y)\n",
    "        self._nrr = NormRowRegressor()\n",
    "        self._nrr.fit(X, y)\n",
    "        \n",
    "        self._other_clf = {}\n",
    "        \n",
    "        if other_clf:\n",
    "            for feature, clf in other_clf.items():\n",
    "                _x = X_returns.copy()\n",
    "                _x[feature] = X[feature]\n",
    "                _x = _x.dropna(subset=[feature])\n",
    "\n",
    "                if not _x.size:\n",
    "                    continue\n",
    "\n",
    "                _y = y.loc[_x.index]\n",
    "                clf.fit(_x, _y)\n",
    "                self._other_clf[feature] = clf\n",
    "\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_returns = self._get_xrtns(X)\n",
    "        out1 = self._dr.predict(X_returns)\n",
    "        out2 = self._nrr.predict(X_returns)\n",
    "        avg = odo(np.average(np.swapaxes(np.array([out1, out2]), 0, 1),\n",
    "                             axis=1, weights=self._weights),pd.DataFrame)\n",
    "    \n",
    "        avg1 = pd.DataFrame()\n",
    "        for feature, clf in self._other_clf.items():\n",
    "            _x = X_returns.copy()\n",
    "            _x[feature] = X[feature]\n",
    "            _x = _x.dropna(subset=[feature])\n",
    "            \n",
    "            if not _x.size:\n",
    "                continue\n",
    "\n",
    "            _p = odo(clf.predict(_x), pd.DataFrame)\n",
    "            _p.index = _x.index\n",
    "            avg1 = (avg1).add(_p, fill_value=0)\n",
    "            \n",
    "        avg = (.999*avg).add(.001*avg1, fill_value=0)\n",
    "        \n",
    "        return avg.values\n",
    "\n",
    "\n",
    "# combines arbitrary regressors, can pass in weights, fillna functions, and fit_params\n",
    "class JointRegressor3(BaseEstimator, RegressorMixin):\n",
    "    \n",
    "    def fit(self, X, y, regressors=None, weights=None, fillfn=fillall0, fit_params=None):\n",
    "        self._fillfn = fillfn\n",
    "        X = self._fillfn(X)\n",
    "        y = self._fillfn(y)\n",
    "        if regressors is None:\n",
    "            raise Exception('You done goofed!')        \n",
    "        self._weights = weights\n",
    "        self._regressors = []       \n",
    "        \n",
    "        if fit_params is None:\n",
    "            fit_params = [{}]*len(regressors)\n",
    "\n",
    "        reg_and_params = zip(regressors, fit_params)\n",
    "        for clf, _fit_params in reg_and_params:\n",
    "            clf.fit(X, y, **_fit_params)\n",
    "            self._regressors.append(clf)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X = self._fillfn(X)\n",
    "        outs = []\n",
    "        for regressor in self._regressors:\n",
    "            outs.append(regressor.predict(X))\n",
    "        \n",
    "        arr = np.swapaxes(np.array(outs,dtype=np.float32), 0, 1)\n",
    "        marr = np.ma.masked_array(arr,np.isnan(arr))\n",
    "        avg = np.ma.average(marr, axis=1, weights=self._weights)\n",
    "        return avg.filled(0)\n",
    "\n",
    "\n",
    "from statsmodels.tsa.arima_model import ARMA\n",
    "\n",
    "class ARMARegressor(BaseEstimator, RegressorMixin):\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        out = pd.DataFrame()\n",
    "\n",
    "        def arma_predict(s):\n",
    "            try:\n",
    "                am = ARMA(s.values, (3, 2)).fit(warn_convergence=False)\n",
    "                p = am.predict(119,178)\n",
    "                return odo(np.concatenate([p,[0,0]]), pd.Series)\n",
    "            except:\n",
    "                return odo([0]*62, pd.Series)\n",
    "\n",
    "        _X = X.loc[:, 'Ret_2':'Ret_120']\n",
    "        r = _X.apply(arma_predict, axis=1)\n",
    "        return r.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DummyRegressor Accuracy: 1773.78450 (+/- 27.11001)\n"
     ]
    }
   ],
   "source": [
    "# baseline using a simple regressor that returns the median of target values\n",
    "from sklearn import cross_validation\n",
    "clf = DummyRegressor(strategy='median')\n",
    "scores = cross_validation.cross_val_score(\n",
    "    clf, X.fillna(0), Y.fillna(0), cv=5, scoring=wmae_score)\n",
    "print(\"%s Accuracy: %0.5f (+/- %0.5f)\" % (\n",
    "        clf.__class__.__name__, scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointRegressor3 Accuracy: 1773.83220 (+/- 26.93983)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import cross_validation\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "feats1 = set(df.loc[:,'Feature_1':'Feature_25'].columns) - nuke_features\n",
    "catfeats1 = set(feature_cats) - nuke_features\n",
    "\n",
    "def testit(clf, fit_params={}):\n",
    "    scores = cross_validation.cross_val_score(\n",
    "        clf, X, Y, cv=5, scoring=wmae_score, fit_params=fit_params)\n",
    "    print(\"%s Accuracy: %0.5f (+/- %0.5f)\" % (\n",
    "            clf.__class__.__name__, scores.mean(), scores.std() * 2))\n",
    "\n",
    "fit_params = {\n",
    "    'weights':[1,1],\n",
    "    'fillfn':fillall2,\n",
    "    'regressors': [\n",
    "        DummyRegressor(strategy='median'),\n",
    "        NormRowRegressor()\n",
    "    ]\n",
    "}\n",
    "\n",
    "clf = JointRegressor3()\n",
    "testit(clf, fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointRegressor3 Accuracy: 1737.13655 (+/- 30.25603)\n"
     ]
    }
   ],
   "source": [
    "fit_params = {\n",
    "    'weights':[1,1,1,1],\n",
    "    'regressors': [\n",
    "        DummyRegressor(strategy='median'),\n",
    "        FeatureMeanRegressor2(feats1),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_PlusTwo','Ret_PlusTwo'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=100)),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_PlusOne','Ret_PlusOne'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=100))\n",
    "    ]\n",
    "}\n",
    "\n",
    "clf = JointRegressor3()\n",
    "testit(clf, fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointRegressor3 Accuracy: 1764.69820 (+/- 26.99498)\n"
     ]
    }
   ],
   "source": [
    "msl = 200\n",
    "n_estimators = 100\n",
    "\n",
    "fit_params = {\n",
    "    'weights':[8,1, 1,1,1,1,1,1,1, 1,1,1,1,1,1, 1,1],\n",
    "    'regressors': [\n",
    "        DummyRegressor(strategy='median'),\n",
    "        FeatureMeanRegressor2(feats1),\n",
    "\n",
    "        RetMeanRegressor(['Ret_MinusTwo','Ret_MinusOne']),\n",
    "        RetMeanRegressor(['Ret_2','Ret_120'], ['Ret_121','Ret_130']),\n",
    "        RetMeanRegressor(['Ret_12','Ret_120'], ['Ret_131','Ret_140']),\n",
    "        RetMeanRegressor(['Ret_22','Ret_120'], ['Ret_141','Ret_150']),\n",
    "        RetMeanRegressor(['Ret_32','Ret_120'], ['Ret_151','Ret_160']),\n",
    "        RetMeanRegressor(['Ret_42','Ret_120'], ['Ret_161','Ret_170']),\n",
    "        RetMeanRegressor(['Ret_52','Ret_120'], ['Ret_171','Ret_180']),\n",
    "        \n",
    "        FeatureMeanRegressor2(feats1, ['Ret_121','Ret_130'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_131','Ret_140'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_141','Ret_150'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_151','Ret_160'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_161','Ret_170'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "        FeatureMeanRegressor2(feats1, ['Ret_171','Ret_180'],\n",
    "                              DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "\n",
    "        FeatureMeanRegressor2(\n",
    "            feats1, ['Ret_PlusTwo','Ret_PlusTwo'],\n",
    "            GradientBoostingRegressor(n_estimators=1000, min_samples_leaf=msl)),        \n",
    "        FeatureMeanRegressor2(\n",
    "            feats1, ['Ret_PlusOne','Ret_PlusOne'],\n",
    "            GradientBoostingRegressor(n_estimators=1000, min_samples_leaf=msl))\n",
    "    ]\n",
    "}\n",
    "\n",
    "clf = JointRegressor3()\n",
    "testit(clf, fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JointRegressor3 Accuracy: 1765.09410 (+/- 27.59929)\n"
     ]
    }
   ],
   "source": [
    "msl = 200\n",
    "ne = 100\n",
    "\n",
    "def build_fit_params():\n",
    "    fit_params = {\n",
    "        'weights':[1,1,1,1,1],\n",
    "        'fillfn':fillall2,\n",
    "        'regressors': [\n",
    "            FeatureMeanRegressor2(feats1),\n",
    "            FeatureMeanRegressor2(\n",
    "                feats1, ['Ret_PlusTwo','Ret_PlusTwo'],\n",
    "                DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "            FeatureMeanRegressor2(\n",
    "                feats1, ['Ret_PlusOne','Ret_PlusOne'],\n",
    "                DecisionTreeRegressor(min_samples_leaf=msl)),\n",
    "            FeatureMeanRegressor2(\n",
    "                feats1, ['Ret_PlusTwo','Ret_PlusTwo'],\n",
    "                GradientBoostingRegressor(n_estimators=ne,min_samples_leaf=msl)),\n",
    "            FeatureMeanRegressor2(\n",
    "                feats1, ['Ret_PlusOne','Ret_PlusOne'],\n",
    "                GradientBoostingRegressor(n_estimators=ne,min_samples_leaf=msl))\n",
    "        ]\n",
    "    }\n",
    "    return fit_params\n",
    "\n",
    "\n",
    "fit_params = {\n",
    "    'weights':[16,1,1,1],\n",
    "    'regressors': [\n",
    "        DummyRegressor(strategy='median'),\n",
    "        JointRegressor3(),\n",
    "        JointRegressor3(),\n",
    "        JointRegressor3()\n",
    "    ],\n",
    "    'fit_params': [\n",
    "        {},\n",
    "        build_fit_params(),\n",
    "        build_fit_params(),\n",
    "        build_fit_params()\n",
    "    ]\n",
    "}\n",
    "\n",
    "clf = JointRegressor3()\n",
    "testit(clf, fit_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write out predictions to file\n",
    "clf.fit(X, Y, **fit_params)\n",
    "Y_hat = clf.predict(X_test)\n",
    "write_predictions(Y_hat)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
